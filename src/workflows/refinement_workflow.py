"""
Workflow LangGraph para refinamento iterativo de conte√∫do

Ciclo: Gerar ‚Üí Avaliar ‚Üí Refinar ‚Üí Repetir at√© qualidade adequada
"""
from typing import Dict, Literal
from datetime import datetime
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage
from langgraph.graph import StateGraph, END
from src.workflows.states import ContentRefinementState
from src.config.settings import settings

class ContentRefinementWorkflow:
    """
    Workflow de refinamento iterativo com avalia√ß√£o autom√°tica
    """
    
    def __init__(self):
        self.llm = ChatOpenAI(
            model=settings.OPENAI_MODEL,
            temperature=0.7,
            openai_api_key=settings.OPENAI_API_KEY
        )
        
        self.evaluator_llm = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0.2,
            openai_api_key=settings.OPENAI_API_KEY
        )
        
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """Constr√≥i o grafo de refinamento"""
        
        workflow = StateGraph(ContentRefinementState)
        
        # Adicionar n√≥s
        workflow.add_node("evaluate", self._evaluate_node)
        workflow.add_node("refine", self._refine_node)
        workflow.add_node("complete", self._complete_node)
        
        # Definir fluxo
        workflow.set_entry_point("evaluate")
        
        # Decis√£o ap√≥s avalia√ß√£o
        workflow.add_conditional_edges(
            "evaluate",
            self._should_refine,
            {
                "refine": "refine",
                "complete": "complete"
            }
        )
        
        # Loop: refinar volta para avaliar
        workflow.add_edge("refine", "evaluate")
        workflow.add_edge("complete", END)
        
        return workflow.compile()
    
    def _evaluate_node(self, state: ContentRefinementState) -> ContentRefinementState:
        """Avalia a qualidade do conte√∫do atual"""
        print(f"üìä Avaliando qualidade (itera√ß√£o {state['iteration']})...")
        
        content = state['current_version'] if state['iteration'] > 0 else state['content']
        
        try:
            # Avaliar com LLM
            evaluation_prompt = self._build_evaluation_prompt(content, state['content_type'])
            
            messages = [
                SystemMessage(content="Voc√™ √© um avaliador de qualidade de conte√∫do educacional para professores."),
                HumanMessage(content=evaluation_prompt)
            ]
            
            response = self.evaluator_llm.invoke(messages)
            
            # Parse score (simplificado)
            score = self._parse_quality_score(response.content)
            feedback = self._extract_feedback(response.content)
            
            state['quality_scores'].append(score)
            state['quality_feedback'].append(feedback)
            
            print(f"   ‚Üí Score: {score:.2f}")
            print(f"   ‚Üí Feedback: {feedback[:80]}...")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro na avalia√ß√£o: {e}")
            # Score m√©dio como fallback
            score = 0.7
            state['quality_scores'].append(score)
            state['quality_feedback'].append("Avalia√ß√£o autom√°tica indispon√≠vel")
        
        return state
    
    def _refine_node(self, state: ContentRefinementState) -> ContentRefinementState:
        """Refina o conte√∫do baseado no feedback"""
        print(f"üîß Refinando conte√∫do...")
        
        try:
            # Pegar √∫ltima avalia√ß√£o
            latest_feedback = state['quality_feedback'][-1] if state['quality_feedback'] else "Melhorar clareza e estrutura"
            
            refinement_prompt = self._build_refinement_prompt(
                state['current_version'],
                latest_feedback,
                state['content_type']
            )
            
            messages = [
                SystemMessage(content="Voc√™ √© um especialista em refinamento de conte√∫do educacional."),
                HumanMessage(content=refinement_prompt)
            ]
            
            response = self.llm.invoke(messages)
            refined = response.content
            
            # Salvar vers√£o refinada
            state['refined_versions'].append(refined)
            state['current_version'] = refined
            state['iteration'] += 1
            
            # Log de melhoria
            improvement = {
                "iteration": state['iteration'],
                "feedback_applied": latest_feedback[:100],
                "timestamp": str(datetime.utcnow())
            }
            state['improvement_log'].append(improvement)
            
            print(f"   ‚úì Vers√£o refinada {state['iteration']}")
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è Erro no refinamento: {e}")
        
        return state
    
    def _complete_node(self, state: ContentRefinementState) -> ContentRefinementState:
        """Finaliza o processo de refinamento"""
        print(f"‚úÖ Refinamento conclu√≠do!")
        
        state['final_content'] = state['current_version']
        state['final_quality'] = state['quality_scores'][-1] if state['quality_scores'] else 0.0
        state['converged'] = True
        
        # Determinar raz√£o de conclus√£o
        if state['iteration'] >= state['max_iterations']:
            state['reason'] = f"Limite de itera√ß√µes atingido ({state['max_iterations']})"
        elif state['final_quality'] >= state['target_quality']:
            state['reason'] = f"Qualidade alvo atingida ({state['final_quality']:.2f} >= {state['target_quality']:.2f})"
        else:
            state['reason'] = "Converg√™ncia prematura"
        
        print(f"   ‚Üí Raz√£o: {state['reason']}")
        print(f"   ‚Üí Qualidade final: {state['final_quality']:.2f}")
        print(f"   ‚Üí Itera√ß√µes: {state['iteration']}")
        
        return state
    
    def _should_refine(self, state: ContentRefinementState) -> Literal["refine", "complete"]:
        """Decide se deve refinar ou completar"""
        
        # Verificar limite de itera√ß√µes
        if state['iteration'] >= state['max_iterations']:
            return "complete"
        
        # Verificar qualidade
        if state['quality_scores']:
            latest_score = state['quality_scores'][-1]
            if latest_score >= state['target_quality']:
                return "complete"
        
        # Verificar converg√™ncia (score n√£o melhora)
        if len(state['quality_scores']) >= 2:
            improvement = state['quality_scores'][-1] - state['quality_scores'][-2]
            if improvement < 0.02:  # Melhoria m√≠nima
                print(f"   ‚Üí Converg√™ncia detectada (melhoria: {improvement:.3f})")
                return "complete"
        
        return "refine"
    
    def _build_evaluation_prompt(self, content: str, content_type: str) -> str:
        """Constr√≥i prompt de avalia√ß√£o"""
        return f"""
Avalie a qualidade deste {content_type} para treinamento de professores:

**Conte√∫do:**
{content[:500]}...

**Crit√©rios de Avalia√ß√£o:**
1. Clareza e objetividade
2. Relev√¢ncia para professores
3. Estrutura e organiza√ß√£o
4. Aplicabilidade pr√°tica
5. Linguagem adequada

Forne√ßa:
- Score de 0 a 1 (formato: "SCORE: 0.XX")
- Feedback espec√≠fico para melhorias

Responda em formato estruturado.
"""
    
    def _build_refinement_prompt(self, content: str, feedback: str, content_type: str) -> str:
        """Constr√≥i prompt de refinamento"""
        return f"""
Refine este {content_type} com base no feedback:

**Conte√∫do Atual:**
{content}

**Feedback:**
{feedback}

**Instru√ß√µes:**
- Mantenha o mesmo tamanho aproximado
- Aplique as sugest√µes do feedback
- Melhore clareza e estrutura
- Mantenha foco em professores como p√∫blico

Retorne APENAS o conte√∫do refinado.
"""
    
    def _parse_quality_score(self, evaluation: str) -> float:
        """Extrai score da avalia√ß√£o"""
        import re
        
        # Procurar padr√£o "SCORE: 0.XX"
        match = re.search(r'SCORE:\s*([0-9.]+)', evaluation, re.IGNORECASE)
        if match:
            try:
                score = float(match.group(1))
                return max(0.0, min(1.0, score))
            except:
                pass
        
        # Fallback: score m√©dio
        return 0.7
    
    def _extract_feedback(self, evaluation: str) -> str:
        """Extrai feedback textual"""
        # Simplificado: pegar tudo ap√≥s "Feedback"
        import re
        
        match = re.search(r'Feedback[:\s]*(.+)', evaluation, re.IGNORECASE | re.DOTALL)
        if match:
            return match.group(1).strip()[:200]
        
        return evaluation[:200]
    
    def run(
        self, 
        content: str, 
        content_type: str = "script",
        target_quality: float = 0.85,
        max_iterations: int = 5
    ) -> Dict:
        """
        Executa refinamento iterativo
        
        Args:
            content: Conte√∫do inicial
            content_type: Tipo ('script', 'outline', 'summary')
            target_quality: Qualidade alvo (0-1)
            max_iterations: M√°ximo de itera√ß√µes
        
        Returns:
            Conte√∫do refinado e metadata
        """
        
        from datetime import datetime
        
        # Estado inicial
        initial_state: ContentRefinementState = {
            "content": content,
            "content_type": content_type,
            "target_quality": target_quality,
            "quality_scores": [],
            "quality_feedback": [],
            "refined_versions": [],
            "current_version": content,
            "iteration": 0,
            "max_iterations": max_iterations,
            "final_content": None,
            "final_quality": None,
            "improvement_log": [],
            "converged": False,
            "reason": None
        }
        
        print(f"\nüîÑ Iniciando refinamento iterativo")
        print(f"   Tipo: {content_type}")
        print(f"   Qualidade alvo: {target_quality:.2f}")
        print(f"   Max itera√ß√µes: {max_iterations}")
        print("=" * 60)
        
        # Executar workflow
        final_state = self.graph.invoke(initial_state)
        
        print("=" * 60)
        
        return {
            "success": final_state['converged'],
            "content": final_state['final_content'],
            "quality": final_state['final_quality'],
            "metadata": {
                "iterations": final_state['iteration'],
                "quality_progression": final_state['quality_scores'],
                "improvement_log": final_state['improvement_log'],
                "reason": final_state['reason']
            }
        }
